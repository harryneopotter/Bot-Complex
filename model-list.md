|Provider  |Category        |Model Name (Platform)                                                   |Requests/min|Requests/day|Tokens/min|Tokens/day|Audio sec/hour|Audio sec/day|Notes                                                                             |
|----------|----------------|------------------------------------------------------------------------|------------|------------|----------|----------|--------------|-------------|----------------------------------------------------------------------------------|
|Groq      |Chat Completions|allam-2-7b                                                              |30          |7,000       |6,000     |500,000   |              |             |Prefer Meta Llama 3.2 3B Turbo (Together) for cleaner instruction-following       |
|Groq      |Chat Completions|compound-beta                                                           |15          |200         |70,000    |No limit  |              |             |Prefer Meta Llama 3.1 8B Turbo (Together) for stability; GPT-OSS 20B for reasoning|
|Groq      |Chat Completions|compound-beta-mini                                                      |15          |200         |70,000    |No limit  |              |             |Prefer Llama 3.2 3B Turbo (Together) for low-cost instruction tasks               |
|Groq      |Chat Completions|deepseek-r1-distill-llama-70b                                           |30          |1,000       |6,000     |100,000   |              |             |Keep for heavyweight reasoning; see paid notes in master table                    |
|Groq      |Chat Completions|gemma2-9b-it                                                            |30          |14,400      |15,000    |500,000   |              |             |Comparable to 8B-class paid, use Llama 3.1 8B Turbo for prod stability            |
|Groq      |Chat Completions|llama-3.1-8b-instant                                                    |30          |14,400      |6,000     |500,000   |              |             |Llama 3.1 8B Turbo is more consistent for prod workloads                          |
|Groq      |Chat Completions|llama-3.3-70b-versatile                                                 |30          |1,000       |12,000    |100,000   |              |             |Keep for general reasoning; see paid notes in master table                        |
|Groq      |Chat Completions|llama3-70b-8192                                                         |30          |14,400      |6,000     |500,000   |              |             |See previous note                                                                 |
|Groq      |Chat Completions|llama3-8b-8192                                                          |30          |14,400      |6,000     |500,000   |              |             |Prefer Llama 3.1 8B Turbo for stability                                           |
|Groq      |Chat Completions|meta-llama/llama-4-maverick-17b-128e-instruct                           |30          |1,000       |6,000     |500,000   |              |             |See previous note                                                                 |
|Groq      |Chat Completions|meta-llama/llama-4-scout-17b-16e-instruct                               |30          |1,000       |30,000    |500,000   |              |             |For controlled style, see paid suggestions                                        |
|Groq      |Chat Completions|meta-llama/llama-guard-4-12b                                            |30          |14,400      |15,000    |500,000   |              |             |For safety, use Llama Guard paid (Together) for production moderation             |
|Groq      |Chat Completions|meta-llama/llama-prompt-guard-2-22m                                     |30          |14,400      |15,000    |500,000   |              |             |Good as prefilter, paid Guard for prod                                            |
|Groq      |Chat Completions|meta-llama/llama-prompt-guard-2-86m                                     |30          |14,400      |15,000    |500,000   |              |             |Good as prefilter, paid Guard for prod                                            |
|Groq      |Chat Completions|moonshotai/kimi-k2-instruct                                             |60          |1,000       |10,000    |300,000   |              |             |For deterministic outputs, see paid list                                          |
|Groq      |Chat Completions|openai/gpt-oss-120b                                                     |30          |1,000       |8,000     |200,000   |              |             |Large; see paid for mid-tier reasoning                                            |
|Groq      |Chat Completions|openai/gpt-oss-20b                                                      |30          |1,000       |8,000     |200,000   |              |             |Also appears in paid shortlist                                                    |
|Groq      |Chat Completions|qwen/qwen3-32b                                                          |60          |1,000       |6,000     |500,000   |              |             |Strong, but Qwen2.5 7B Turbo is more cost-effective                               |
|Groq      |Speech to Text  |distil-whisper-large-v3-en                                              |20          |2,000       |          |          |7,200         |28,800       |Commercial STT only if accuracy needed                                            |
|Groq      |Speech to Text  |whisper-large-v3                                                        |20          |2,000       |          |          |7,200         |28,800       |Same as above                                                                     |
|Groq      |Speech to Text  |whisper-large-v3-turbo                                                  |20          |2,000       |          |          |7,200         |28,800       |Turbo is fast, go paid only for accuracy                                          |
|Groq      |Text to Speech  |playai-tts                                                              |10          |100         |1,200     |3,600     |              |             |Paid TTS for features/SSML/control                                                |
|Groq      |Text to Speech  |playai-tts-arabic                                                       |10          |100         |1,200     |3,600     |              |             |Same as above                                                                     |
|Together  |Chat Completions|Meta Llama Vision Free (togethercomputer/llama-v)                       |600         |            |          |          |              |             |See Meta Llama 3.2 11B Vision Turbo (paid) for higher OCR, multimodal             |
|Together  |Chat Completions|DeepSeek R1 Distill Llama 70B Free (deepseek-ai/deepseek-llm-70b)       |600         |            |          |          |              |             |Keep for heavy reasoning                                                          |
|Together  |Chat Completions|EXAONE Deep 32B Free (exaone/deep-32b)                                  |600         |            |          |          |              |             |Qwen2.5 7B Turbo for prod outputs                                                 |
|Together  |Chat Completions|EXAONE 3.5 32B Instruct Free (exaone/instruct-32b)                      |600         |            |          |          |              |             |Qwen2.5 7B Turbo for steadier instruction adherence                               |
|Together  |Chat Completions|Meta Llama 3.3 70B Instruct Turbo Free (meta-llama/llama-3-70b-instruct)|600         |            |          |          |              |             |Keep for quality                                                                  |
|Together  |Image Generation|FLUX.1 [schnell] Free (flux-ai/flux-1-schnell)                          |600         |            |          |          |              |             |Paid image models for high fidelity/controls                                      |
|OpenRouter|Chat Completions|DeepSeek V3 0324 (deepseek-ai/deepseek-v3-32-4:free)                    |20          |1000        |          |          |              |             |MoE 685B, multi-step/global reasoning, high context                               |
|OpenRouter|Chat Completions|DeepSeek R1 0528 (deepseek-ai/deepseek-r1:free)                         |20          |1000        |          |          |              |             |Latest Open OSS DeepSeek, benchmarking, licensing                                 |
|OpenRouter|Coding          |Qwen3 Coder (qwen/qwen3-coder:free)                                     |20          |1000        |          |          |              |             |MoE code specialist, 262K context, strong for repo/code agent                     |
|OpenRouter|Chat Completions|Z.AI GLM 4.5 Air (z-ai/glm-4.5-air:free)                                |20          |1000        |          |          |              |             |Lightweight agentic/thinking model, chaining                                      |
|OpenRouter|Chat Completions|TNG DeepSeek R1T2 Chimera (tng-ai/deepseek-r1t2-chimera:free)           |20          |1000        |          |          |              |             |Ensemble DeepSeek, improved efficiency                                            |
|OpenRouter|Coding          |MoonshotAI Kimi K2 (moonshot-ai/kimi-k2:free)                           |20          |1000        |          |          |              |             |MoE, logic/coding, SWE-bench performer                                            |
|OpenRouter|Chat Completions|Google Gemini 2.0 Flash Experimental (google/gemini-2.0-flash:free)     |20          |1000        |          |          |              |             |Huge context window 1M+, multimodal, fast TTFT                                    |
|Together (Paid)|Chat Completions|Meta Llama 3.2 3B Instruct Turbo (togethercomputer/llama-3-3b-instruct-turbo)|600         |            |          |          |              |             |$0.06 — stable instruction-follow.                                                |
|Together (Paid)|Chat Completions|Meta Llama 3.1 8B Instruct Turbo (togethercomputer/llama-3-8b-instruct-turbo)|600         |            |          |          |              |             |$0.18 — balanced quality/latency.                                                 |
|Together (Paid)|Chat Completions|Qwen2.5 7B Instruct Turbo (qwen/qwen2-7b-instruct-turbo)                |600         |            |          |          |              |             |$0.30 — strong 7B reasoning/coding.                                               |
|Together (Paid)|Chat Completions|OpenAI GPT-OSS 20B (openai/gpt-oss-20b)                                 |600         |            |          |          |              |             |$0.05(in)/$0.20(out) — mid-tier reasoning.                                        |
|Together (Paid)|Chat Completions|Upstage SOLAR Instruct v1 (11B) (upstage/solar-instruct-v1-11b)         |600         |            |          |          |              |             |$0.30 — steady style, tone.                                                       |
|Together (Paid)|Vision Chat     |Meta Llama 3.2 11B Vision Instruct Turbo (togethercomputer/llama-v-11b-turbo)|600         |            |          |          |              |             |$0.18 — OCR, chart, table fidelity.                                               |
|Together (Paid)|Reasoning Small |DeepSeek R1 Distill Qwen 1.5B (deepseek-ai/deepseek-r1-distill-qwen-1-5b)|600         |            |          |          |              |             |$0.18 — cost-efficient small reasoning.                                           |
|Together (Paid)|Moderation      |Llama Guard 3/4 (8–12B) (meta-llama/llama-guard-4-12b)                  |600         |            |          |          |              |             |$0.18–$0.20 — enhanced safety.                                                    |
|Together (Paid)|Embeddings      |M2-BERT-Retrieval-32k (togethercomputer/m2-bert-retrieval-32k)          |600         |            |          |          |              |             |$0.01 — embeddings for RAG.                                                       |
|Together (Paid)|Embeddings      |BAAI-BGE-Base-1.5 (baai/bge-base-1.5)                                   |600         |            |          |          |              |             |$0.01 — baseline embeddings.                                                      |
|Together (Paid)|Embeddings      |Multilingual E5 Large Instruct (intfloat/multilingual-e5-large-instruct)|600         |            |          |          |              |             |$0.02 — multi-language embeddings.                                                |
|Together (Paid)|Embeddings      |BAAI-BGE-Large-1.5 (baai/bge-large-1.5)                                 |600         |            |          |          |              |             |$0.02 — higher semantic fidelity.                                                 |